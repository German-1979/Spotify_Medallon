{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b647f5a-8221-430d-b10e-faadded7e87b",
   "metadata": {},
   "source": [
    "### üîß Par√°metros din√°micos (papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c7f025-bb74-426d-b4c9-37a62d520fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "raw_path = \"../data/raw\"\n",
    "bronze_path = \"../data/bronze\"\n",
    "silver_path = \"../data/silver\"\n",
    "gold_path = \"../data/gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54fa97-26fc-4bba-9547-25783049feee",
   "metadata": {},
   "source": [
    "### Importaci√≥n de Librer√≠as y M√≥dulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ebe5ec",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1762105400600,
     "user": {
      "displayName": "Germ√°n Dom√≠nguez",
      "userId": "14788646191146217028"
     },
     "user_tz": 180
    },
    "id": "d4ebe5ec"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import polars as pl\n",
    "import kagglehub\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c739e-095a-4b82-bf2c-e733151cb77f",
   "metadata": {},
   "source": [
    "### üìÅ Validar rutas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4499dae-db48-45d2-8ad2-b1aa6d31641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] Carpetas validadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "for p in [raw_path, bronze_path, silver_path, gold_path]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    \n",
    "print(\"[setup] Carpetas validadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64384b2-5599-4563-ab0f-20fa70c76de7",
   "metadata": {},
   "source": [
    "### Extract √∫nico: descargar CSV a raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7925680c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3402,
     "status": "ok",
     "timestamp": 1762105404005,
     "user": {
      "displayName": "Germ√°n Dom√≠nguez",
      "userId": "14788646191146217028"
     },
     "user_tz": 180
    },
    "id": "7925680c",
    "outputId": "ef8275ef-056c-4f82-8f97-71fd409af07b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[extract_to_raw] Carpeta raw lista en: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\raw\n",
      "[extract_to_raw] Dataset descargado en cache: C:\\Users\\germa\\.cache\\kagglehub\\datasets\\zaheenhamidani\\ultimate-spotify-tracks-db\\versions\\3\n",
      "[extract_to_raw] Copiado a raw: SpotifyFeatures.csv\n",
      "[extract_to_raw] CSV disponibles en raw: ['SpotifyFeatures.csv']\n",
      "\n",
      "Archivos CSV descargados en raw:\n",
      " - C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\raw\\SpotifyFeatures.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_to_raw(base_path: str | None = None) -> list[str]:\n",
    "    \"\"\"\n",
    "    Descarga el dataset 'Ultimate Spotify Tracks DB' desde Kaggle y\n",
    "    copia los archivos CSV a la carpeta 'data/raw' dentro de base_path.\n",
    "\n",
    "    Args:\n",
    "        base_path (str | None): Ruta ra√≠z del proyecto. Si es None, se determina autom√°ticamente.\n",
    "            - En script (.py): usa __file__.\n",
    "            - En notebook: usa el directorio de trabajo actual.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: Rutas completas de los CSV copiados a la carpeta 'data/raw'.\n",
    "    \"\"\"\n",
    "    # Determinar base_path si no se pasa\n",
    "    if base_path is None:\n",
    "        try:\n",
    "            base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "        except NameError:\n",
    "            # Estamos en un notebook\n",
    "            base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "    raw_path = os.path.join(base_path, \"data\", \"raw\")  # <-- aqu√≠ se corrige\n",
    "    os.makedirs(raw_path, exist_ok=True)\n",
    "    print(f\"[extract_to_raw] Carpeta raw lista en: {raw_path}\")\n",
    "\n",
    "    # Descargar dataset desde Kaggle (se guarda en cache local)\n",
    "    cache_path = kagglehub.dataset_download(\"zaheenhamidani/ultimate-spotify-tracks-db\")\n",
    "    print(f\"[extract_to_raw] Dataset descargado en cache: {cache_path}\")\n",
    "\n",
    "    csv_files = []\n",
    "\n",
    "    # Copiar solo los CSV a raw, ignorando cualquier carpeta interna\n",
    "    for root, dirs, files in os.walk(cache_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".csv\"):\n",
    "                src = os.path.join(root, file_name)\n",
    "                dst = os.path.join(raw_path, file_name)\n",
    "                shutil.copy(src, dst)\n",
    "                csv_files.append(dst)\n",
    "                print(f\"[extract_to_raw] Copiado a raw: {file_name}\")\n",
    "\n",
    "    print(f\"[extract_to_raw] CSV disponibles en raw: {[os.path.basename(f) for f in csv_files]}\")\n",
    "    return csv_files\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Ejecuci√≥n directa (script o notebook)\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    csv_files = extract_to_raw()  # base_path se determina autom√°ticamente\n",
    "    print(\"\\nArchivos CSV descargados en raw:\")\n",
    "    for f in csv_files:\n",
    "        print(\" -\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28e80e-7022-4305-a59a-0744fc5be2f4",
   "metadata": {},
   "source": [
    "### Load Bronze: leer CSV tal cual y agregar timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3800b78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1762105600727,
     "user": {
      "displayName": "Germ√°n Dom√≠nguez",
      "userId": "14788646191146217028"
     },
     "user_tz": 180
    },
    "id": "a3800b78",
    "outputId": "7b3db856-785c-49c2-97c7-a41728ff1372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Guardado en bronze completado: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\bronze\\SpotifyFeatures_bronze.parquet con 232725 filas\n"
     ]
    }
   ],
   "source": [
    "def load_bronze(csv_path: str | None = None, bronze_path: str | None = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Lee un CSV desde raw, agrega timestamp de ingesta y guarda en bronze\n",
    "    sin hacer ninguna transformaci√≥n.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str | None): Ruta del CSV original (raw). Si None, se determina autom√°ticamente.\n",
    "        bronze_path (str | None): Carpeta donde se guardar√° el Parquet bronze. Si None, se determina autom√°ticamente.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame cargado con columna de timestamp.\n",
    "    \"\"\"\n",
    "    # Determinar base_path si es necesario\n",
    "    if csv_path is None or bronze_path is None:\n",
    "        try:\n",
    "            base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "        except NameError:\n",
    "            # Modo notebook\n",
    "            base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "        if csv_path is None:\n",
    "            csv_path = os.path.join(base_path, \"data\", \"raw\", \"SpotifyFeatures.csv\")\n",
    "        if bronze_path is None:\n",
    "            bronze_path = os.path.join(base_path, \"data\", \"bronze\")\n",
    "\n",
    "    os.makedirs(bronze_path, exist_ok=True)\n",
    "\n",
    "    # Leer CSV usando Polars\n",
    "    df = pl.read_csv(csv_path, use_pyarrow=True, encoding=\"utf8\")\n",
    "\n",
    "    # Agregar timestamp de ingesta\n",
    "    df = df.with_columns([\n",
    "        pl.lit(datetime.now()).cast(pl.Datetime(\"us\")).alias(\"ingest_timestamp\")\n",
    "    ])\n",
    "\n",
    "    # Guardar en bronze como Parquet\n",
    "    file_name = os.path.basename(csv_path).replace(\".csv\", \"_bronze.parquet\")\n",
    "    bronze_file = os.path.join(bronze_path, file_name)\n",
    "    df.write_parquet(bronze_file)\n",
    "\n",
    "    print(f\"‚úÖ Guardado en bronze completado: {bronze_file} con {len(df)} filas\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Ejecuci√≥n directa segura\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\" or ('raw_path' in globals() and 'bronze_path' in globals()):\n",
    "    df_bronze = load_bronze()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55571596-4d75-4817-b9a5-2be7fa115596",
   "metadata": {},
   "source": [
    "### Transform Silver: limpieza y guardado incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0b9208-8197-45e4-adac-5c7c01ab9fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transformaci√≥n a Silver completada: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\silver\\SpotifyFeatures_silver.parquet\n"
     ]
    }
   ],
   "source": [
    "def transform_silver(bronze_file: str | None = None,\n",
    "                     silver_path: str | None = None,\n",
    "                     output_name: str = \"SpotifyFeatures_silver.parquet\") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Limpieza y transformaci√≥n de Bronze a Silver.\n",
    "\n",
    "    Args:\n",
    "        bronze_file (str | None): Ruta al archivo Parquet Bronze. Si None, se determina autom√°ticamente.\n",
    "        silver_path (str | None): Carpeta donde se guardar√° Silver. Si None, se determina autom√°ticamente.\n",
    "        output_name (str): Nombre del archivo Silver a guardar.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame transformado listo para Silver.\n",
    "    \"\"\"\n",
    "    # Determinar base_path si es necesario\n",
    "    if bronze_file is None or silver_path is None:\n",
    "        try:\n",
    "            base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "        except NameError:\n",
    "            # Modo notebook\n",
    "            base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        if bronze_file is None:\n",
    "            bronze_file = os.path.join(base_path, \"data\", \"bronze\", \"SpotifyFeatures_bronze.parquet\")\n",
    "        if silver_path is None:\n",
    "            silver_path = os.path.join(base_path, \"data\", \"silver\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Leer dataset desde Bronze\n",
    "    df = pl.read_parquet(bronze_file, use_pyarrow=True)\n",
    "\n",
    "    # 2Ô∏è‚É£ Eliminar duplicados\n",
    "    df = df.unique()\n",
    "\n",
    "    # 3Ô∏è‚É£ Detectar columnas por tipo\n",
    "    string_cols = [col for col, dtype in zip(df.columns, df.dtypes) if dtype == pl.Utf8]\n",
    "    numeric_cols = [col for col, dtype in zip(df.columns, df.dtypes) if dtype in [pl.Int64, pl.Float64]]\n",
    "\n",
    "    # 4Ô∏è‚É£ Reemplazar nulos y convertir tipos\n",
    "    if string_cols:\n",
    "        df = df.with_columns([pl.col(col).fill_null(\"N/A\") for col in string_cols])\n",
    "    if numeric_cols:\n",
    "        df = df.with_columns([pl.col(col).cast(pl.Float64).fill_null(float(\"nan\")) for col in numeric_cols])\n",
    "\n",
    "    # 5Ô∏è‚É£ Normalizar strings (title case)\n",
    "    if string_cols:\n",
    "        df = df.with_columns([pl.col(col).str.to_titlecase() for col in string_cols])\n",
    "\n",
    "    # 6Ô∏è‚É£ Transformaciones adicionales: timestamp + duration_s\n",
    "    transformations = [pl.lit(datetime.now()).cast(pl.Datetime(\"us\")).alias(\"processed_timestamp\")]\n",
    "    if \"duration_ms\" in df.columns:\n",
    "        transformations.append((pl.col(\"duration_ms\") / 1000).alias(\"duration_s\"))\n",
    "\n",
    "    df = df.with_columns(transformations)\n",
    "\n",
    "    # Eliminar columna original duration_ms si existe\n",
    "    if \"duration_ms\" in df.columns:\n",
    "        df = df.drop(\"duration_ms\")\n",
    "\n",
    "    # Crear carpeta Silver si no existe\n",
    "    os.makedirs(silver_path, exist_ok=True)\n",
    "\n",
    "    # Guardar Parquet\n",
    "    silver_file = os.path.join(silver_path, output_name)\n",
    "    df.write_parquet(silver_file)\n",
    "\n",
    "    print(f\"‚úÖ Transformaci√≥n a Silver completada: {silver_file}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Ejecuci√≥n directa segura\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\" or ('silver_path' in globals() and 'bronze_path' in globals()):\n",
    "    df_silver = transform_silver()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f8377-d283-42de-93d2-6797ddedf8a8",
   "metadata": {},
   "source": [
    "### Aggregate Gold: agregaci√≥n incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef89d249",
   "metadata": {
    "executionInfo": {
     "elapsed": 10099,
     "status": "aborted",
     "timestamp": 1762105405029,
     "user": {
      "displayName": "Germ√°n Dom√≠nguez",
      "userId": "14788646191146217028"
     },
     "user_tz": 180
    },
    "id": "ef89d249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gold generado y guardado en: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\gold\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "\n",
    "def aggregate_gold(silver_file: str | None = None,\n",
    "                   gold_path: str | None = None,\n",
    "                   genre_file_name: str = \"genre_popularity.parquet\",\n",
    "                   artist_file_name: str = \"artist_features.parquet\") -> None:\n",
    "    \"\"\"\n",
    "    Genera las tablas Gold a partir de Silver.\n",
    "\n",
    "    Args:\n",
    "        silver_file (str | None): Ruta al archivo Silver Parquet. Si None, se determina autom√°ticamente.\n",
    "        gold_path (str | None): Carpeta donde se guardar√° Gold. Si None, se determina autom√°ticamente.\n",
    "        genre_file_name (str): Nombre del archivo de popularidad por g√©nero.\n",
    "        artist_file_name (str): Nombre del archivo de caracter√≠sticas por artista.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1Ô∏è‚É£ Determinar base_path seg√∫n script o notebook\n",
    "    try:\n",
    "        base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "    except NameError:\n",
    "        # Notebook\n",
    "        base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "    # 2Ô∏è‚É£ Definir rutas por defecto si no se pasan\n",
    "    if silver_file is None:\n",
    "        silver_file = os.path.join(base_path, \"data\", \"silver\", \"SpotifyFeatures_silver.parquet\")\n",
    "    if gold_path is None:\n",
    "        gold_path = os.path.join(base_path, \"data\", \"gold\")\n",
    "\n",
    "    # 3Ô∏è‚É£ Crear carpeta Gold si no existe\n",
    "    os.makedirs(gold_path, exist_ok=True)\n",
    "\n",
    "    genre_file = os.path.join(gold_path, genre_file_name)\n",
    "    artist_file = os.path.join(gold_path, artist_file_name)\n",
    "\n",
    "    # 4Ô∏è‚É£ Si ya existen, no recalcular\n",
    "    if os.path.exists(genre_file) and os.path.exists(artist_file):\n",
    "        print(\"‚úÖ Gold ya generado, archivos existentes encontrados.\")\n",
    "        return\n",
    "\n",
    "    # 5Ô∏è‚É£ Leer Silver\n",
    "    df = pl.read_parquet(silver_file, use_pyarrow=True)\n",
    "\n",
    "    # 6Ô∏è‚É£ Tabla 1: Popularidad promedio por g√©nero\n",
    "    genre_popularity = (\n",
    "        df.group_by(\"genre\")\n",
    "          .agg([\n",
    "              pl.col(\"popularity\").mean().alias(\"avg_popularity\"),\n",
    "              pl.count(\"track_id\").alias(\"track_count\")\n",
    "          ])\n",
    "          .sort(\"avg_popularity\", descending=True)\n",
    "    )\n",
    "    genre_popularity.write_parquet(genre_file)\n",
    "\n",
    "    # 7Ô∏è‚É£ Tabla 2: Promedio de caracter√≠sticas musicales por artista\n",
    "    features_cols = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\",\n",
    "                     \"liveness\", \"loudness\", \"speechiness\", \"valence\"]\n",
    "    artist_features = (\n",
    "        df.group_by(\"artist_name\")\n",
    "          .agg([pl.col(col).mean().alias(f\"avg_{col}\") for col in features_cols])\n",
    "    )\n",
    "    artist_features.write_parquet(artist_file)\n",
    "\n",
    "    print(f\"‚úÖ Gold generado y guardado en: {gold_path}\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Ejecuci√≥n directa segura\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\" or ('gold_path' in globals() and 'silver_path' in globals()):\n",
    "    aggregate_gold()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fcb04",
   "metadata": {},
   "source": [
    "### Ejecuci√≥n del Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d82ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Extrayendo datos raw...\n",
      "[extract_to_raw] Carpeta raw lista en: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\raw\n",
      "[extract_to_raw] Dataset descargado en cache: C:\\Users\\germa\\.cache\\kagglehub\\datasets\\zaheenhamidani\\ultimate-spotify-tracks-db\\versions\\3\n",
      "[extract_to_raw] Copiado a raw: SpotifyFeatures.csv\n",
      "[extract_to_raw] CSV disponibles en raw: ['SpotifyFeatures.csv']\n",
      "üöÄ Cargando Bronze...\n",
      "‚úÖ Guardado en bronze completado: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\bronze\\SpotifyFeatures_bronze.parquet con 232725 filas\n",
      "üöÄ Transformando Silver...\n",
      "‚úÖ Transformaci√≥n a Silver completada: C:\\Users\\germa\\Desktop\\Carpetas\\Data_Engineer_Specialist\\Spotify_Medallon\\data\\silver\\SpotifyFeatures_silver.parquet\n",
      "üöÄ Agregando Gold...\n",
      "‚úÖ Gold ya generado, archivos existentes encontrados.\n",
      "‚úÖ Pipeline completado.\n"
     ]
    }
   ],
   "source": [
    "def run_pipeline():\n",
    "    \"\"\"\n",
    "    Ejecuta todo el pipeline ETL de Spotify: raw -> bronze -> silver -> gold\n",
    "    Validando carpetas y archivos en cada paso.\n",
    "    Retorna los DataFrames finales de Bronze y Silver.\n",
    "    \"\"\"\n",
    "    # ------------------------------\n",
    "    # 1Ô∏è‚É£ Determinar base_path\n",
    "    # ------------------------------\n",
    "    try:\n",
    "        base_path = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "    except NameError:\n",
    "        # Modo notebook\n",
    "        base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2Ô∏è‚É£ Definir rutas de carpetas\n",
    "    # ------------------------------\n",
    "    raw_path = os.path.join(base_path, \"data\", \"raw\")\n",
    "    bronze_path = os.path.join(base_path, \"data\", \"bronze\")\n",
    "    silver_path = os.path.join(base_path, \"data\", \"silver\")\n",
    "    gold_path = os.path.join(base_path, \"data\", \"gold\")\n",
    "\n",
    "    # Crear carpetas si no existen\n",
    "    for p in [raw_path, bronze_path, silver_path, gold_path]:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3Ô∏è‚É£ Extraer datos a raw\n",
    "    # ------------------------------\n",
    "    print(\"üöÄ Extrayendo datos raw...\")\n",
    "    try:\n",
    "        csv_files = extract_to_raw(base_path)\n",
    "        if not csv_files:\n",
    "            raise FileNotFoundError(\"No se encontraron CSVs en raw.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en extracci√≥n raw: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4Ô∏è‚É£ Cargar Bronze\n",
    "    # ------------------------------\n",
    "    print(\"üöÄ Cargando Bronze...\")\n",
    "    df_bronze = None\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df_bronze = load_bronze(csv_file, bronze_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cargando Bronze desde {csv_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if df_bronze is None:\n",
    "        print(\"‚ùå No se pudo cargar ning√∫n archivo en Bronze.\")\n",
    "        return None, None\n",
    "\n",
    "    # ------------------------------\n",
    "    # 5Ô∏è‚É£ Transformar Silver\n",
    "    # ------------------------------\n",
    "    print(\"üöÄ Transformando Silver...\")\n",
    "    bronze_file = os.path.join(bronze_path, \"SpotifyFeatures_bronze.parquet\")\n",
    "    try:\n",
    "        df_silver = transform_silver(bronze_file, silver_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error transformando Silver: {e}\")\n",
    "        return df_bronze, None\n",
    "\n",
    "    # ------------------------------\n",
    "    # 6Ô∏è‚É£ Agregar Gold\n",
    "    # ------------------------------\n",
    "    print(\"üöÄ Agregando Gold...\")\n",
    "    silver_file = os.path.join(silver_path, \"SpotifyFeatures_silver.parquet\")\n",
    "    try:\n",
    "        aggregate_gold(silver_file, gold_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generando Gold: {e}\")\n",
    "\n",
    "    print(\"‚úÖ Pipeline completado.\")\n",
    "    return df_bronze, df_silver\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Ejecutar autom√°ticamente\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df_bronze, df_silver = run_pipeline()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Spotify_Medallon)",
   "language": "python",
   "name": "spotify_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
